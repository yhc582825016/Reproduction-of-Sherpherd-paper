# seed: 42
# task_type: bert4rankloss

dataset:
  data_type: 'Math'
  train_data_path: ['./Shepherd/prm_data/v1/train.json']
  val_data_path: ['./Shepherd/prm_data/v1/test.json']
  test_data_path: ['./Shepherd/prm_data/v1/test.json']
  max_src_len: 512
  max_seq_len: 1024
  infer_result: './Shepherd/infer_result'

model:
  model_type: 'mistral'
  offload: false
  model_path: ./llm/mistral-7b

train:
  gradient_accumulation_steps: 1
  learning_rate: 5e-7
  lr_scheduler_type: cosine
  per_device_eval_batch_size: 4
  per_device_train_batch_size: 4
  num_warmup_steps: 100
  weight_decay: 0.1
  num_train_epochs: 2
  Dropout: 0.1
  save_path: ./Shepherd/checkpoint/mistral/prm
  scheduler: CAWR
  T_mult: 1
  rewarm_epoch_num: 1
  decay_rate: 0.999
  decay_steps: 200
  
deepspeed:
  offload: false
  zero_stage: 2

log:
  checkpoint_save_interval: 10000
  eval_epoch_ratio: 0.1
  eval_interval: -1
  project_name: 'RM'
  run_name: '311-mistral-gsm8k-prm'
  output_dir: ./Shepherd/checkpoint/mistral/prm

evaluator:
  data_path: ''
  checkpoint_path: './Shepherd/checkpoint/epoch1-eval-loss-1136.86.pth'
  result_save_path: ''